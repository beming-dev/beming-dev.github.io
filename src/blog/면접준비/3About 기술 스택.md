# Nest.js
DIP(의존성 역정 원칙)
고수준 모듈은 저수준 모듈에 의존해서는 안된다.
둘 다 추상화에 의존해야 한다.
추상화는 구체적인 세부 사항에 의존해서는 안된다.

하위 모듈을 직접 인스턴스를 가져다 쓰지 말아라.

이를 위해서는 의존성 주입(DI)개념도 필요.
생성자에서 주입, or spring과 같은 컨테이너가 자동 주입해줌

Nest.js를 사용하여 데이터베이스에 접근하는 Repository 코드의 인터페이스를 작성하고, 의존성 주입 받아 사용. 데이터베이스의 의존성을 분리하여 사용중임.
원래 Service 코드도 분리하였으나, 개발 코스트 증가가 영향이 더 크다 생각하여 삭제하고 현재는 DB만 분리하여 사용중.
추후 DB를 변경할 일이 생기면 사용해볼 예정

# MongoDB

About은 처음에 2명이 시작한 서비스로, 따로 기획자가 있지 않았습니다. 그때그때 요구사항을 반영하고, 생각나는 것들을 바로바로 적용하는 일이 잦다보니 데이터베이스 스키마의 변경도 잦았습니다. MongoDB는 문서 지향 DB로, JSON 형태로 데이터를 저장하고 NoSQL이기 때문에 데이터 구조 변경이 유연하고 빠릅니다. 그래서 잘 맞는다 생각하여 MongoDB를 결정하였습니다.

MongoDB를 직접 사용해보니, MySQL처럼 복잡하게 DB를 설계하지 않아도 되는 점이 좋았습니다. Join과 같은 연산을 많이 사용하지 않아 쿼리도 복잡하지 않았습니다. 

하지만 한 Collection에 많은 데이터가 들어갈수록 관리에 부담이 느껴지고, populate 연산이 많아질수록 속도가 느려지고, 한번의 GET 요청에 너무 큰 데이터가 전송되는 문제도 있었습니다.

Mongoose라는 javascript mongoDB라이브러리에서 제공하는 기능들을 많이 사용했는데, DB의존성이 강하게 생긴다고 느껴서, 최근에는 Entity를 분리하고, Entity에 핵심 로직을 넣고 DB는 단순 CRUD기능 위주로 작동하게 리팩토링하는 작업을 진행하고 있습니다.

# ELK

에러로그를 시각화하여 웹상에서 빠르게 확인 및 대응을 하고, 로그를 분석해 응답이 많이 들어오는 api, 응답이 느린 api등을 발견하기 위해 사용하고 있습니다.

Filebeat가 Docker log를 수집하면 Logstash에서 데이터를 가공하고, Elastic Search를 통해 인덱싱하면, Kibana에서 시각화된걸 분석하여 확인하고 있습니다.

ElasticSearch는 기본적으로 분산 처리에 특화된 구조를 가지고 있습니다. 인덱싱 요청을 여러 노드가 나누어 처리할 수 있습니다. 색인을 생성할 때 샤드 단위로 나누어 데이터를 저장합니다. 샤드 수를 적절히 선정하면 좋습니다.
병렬 인덱싱: 데이터를 동시에 여러 채널에서 인덱싱 요청을 통해 전송해서 처리 속도를 극대화 합니다. Kafka등 메시지 큐 시스템과 연동해서, 여러 소비자가 동시에 데이터를 보내도록 설계할 수 있습니다.
# Docker
컨테이너 기반의 환경 일관성 제공
빠른 배포 속도와 손쉬운 롤백
개발,테스트,운영이 동일한 환경에서 동작
컨테이너 간 격리
가상머신 대비 자원을 효율적으로 사용.
Docker와 image만 있으면 어디서나 동일한 환경 제공 가능

가상머신은 호스트 OS 위에 하이퍼바이저가 별도의 게스트 OS를 구동시킵니다.
Docker는 호스트 OS의 커널을 공유하여 필요한 라이브러리, 런타임만 포함해 경량화되어 작동합니다.

# AWS
codepipeline, codebuild, codedeploy, IAM, EC2, ECR 등 사용해보았습니다.

AWS에 codepipeline이라는 기능을 사용했습니다. git의 main브랜치가 업데이트 되면, source단계를 트리거합니다. 그러면 소스 코드를 가져와서, build 단계에서 제가 정의해둔 buildspec에 따라 코드를 이미지로 빌드 합니다. 빌드된 이미지는 ECR로 전송되어 저장되고, deploy 단계에서는 EC2가 ECR의 이미지를 가져온 뒤, 컨테이너 형태로 배포합니다.

- codepipeline: 소스-빌드-배포 단계를 각각 커스텀하여 하나의 CI/CD 파이프라인을 구성하게 해줍니다.
- codebuild: 스스 코드를 컴파일, 테스트하여 배포 가능한 패키지를 생성합니다. 
- codedeploy: 코드 빌드 후 자동 배포를 도와줍니다.
- IAM: 리소스 접근 제어 및 보안 관리를 위한 서비스입니다. AWS 자원에 접근할 수 있는 권한을 세부적으로 정의하고 관리합니다.
- EC2: 컴퓨팅환경을 제공합니다.
- ECR: 컨테이너 이미지를 관리하고 저장하는완전 관리형 도케 레지스트리 서비스. Docker 이미지를 저장하고 관리하여 ECS, EC2등으로 컨테이너를 배포할 때 사용. 

# DBSCAN
About은 스터디 기능을 제공합니다.
기존의 스터디 기능은 복잡했습니다.
1지망 2지망 선택이 가능하고 스터디 장소를 직접 선택할 수 있고, 참여 시간도 선택할 수 있었습니다.
그러면 각 장소마다 참여 시간과 1,2지망을 고려해서 스터디가 열릴 수 있다고 판단되면 OPEN 하는 자체 제작 알고리즘을 사용했습니다.

그러나 스터디 참여율이 점점 낮아지며 다른 방식을 고려하게 됐습니다.
다양한 유저의 피드백을 들어본 결과, 다음과 같은 문제점이 있었습니다.
1. 유저가 선택할 사항이 너무 많다.
2. 1,2 지망이 겹치지 않아 가까운 거리임에도 매칭이 잘 안이루어진다.
3. 유저가 장소를 선택하므로 투표에 눈치가 보인다.

그래서 떠올린 방식이 클러스터링 방식입니다. 유저가 선택할 사항을 줄이고, 위의 문제사항들을 전부 해결할 수 있겠다 생각했습니다.

DBSCAN과 K-MEANS 알고리즘이 후보였는데, K-MEANS는 cluster의 개수를 미리 정해줘야 하는 점에서 저희 서비스와 맞지 않았습니다.

그래서 유저가 스터디를 하겠다고 투표 버튼을 누르면, 미리 정해둔 선호 장소를 바탕으로 위도 경도 정보만 전송하고, 그 위도 경도 데이터를 기반으로 DBSCAN 알고리즘을 돌리도록 적용했습니다.

DBSCAN에서는 클러스터 범위와 최소인원만 선택이 가능한데, 알고리즘 결과가 특정 인원을 넘으면 재귀적으로 범위를 줄여서 다시 클러스터링 하는 방식으로 알고리즘을 활용하여 적용했습니다.

이 방식을 사용하면, 최소거리를 직접 조정하며 상황에 맞게 클러스터 범위를 조절할 수 있고, 유저가 할 행동이 줄어서 많은 장점이 있습니다.

# Docker
컨테이너라는 경량화된 가상 환경에서 애플리케이션을 개발, 배포하도록 도와주는 플랫폼.
애플리케이션과 실행되는 환경을 하나의 패키지로 묶어 어느 환경에서든 동일하게 동작하도록 합니다.

가상머신은 하이퍼바이저라는 OS위에 가상 머신을 직접 설치해서 사용하는 방면, Docker는 OS 커널을 공유한다.

볼륨: 컨테이너가 데이터를 영구적으로 저장할 수 있도록 하는 저장소.
컨테이너가 종료되더라도 데이터 유지 가능

네트워크: 컨테이너 간의 통신을 관리

# Redis

최근에, 모든 요청에 대해 처리시간을 로깅하고,  ELK스택으로 url별로 평균 처리시간을 분석하여 시간이 오래 걸리는 API를 분석했습니다.
분석결과 시간이 오래 걸리는 이유가 큰 데이터를 읽어와 처리하기 때문이라 생각했고, 처리 결과를 Redis에 캐싱하여 처리속도를 200ms대에서 100ms 초반으로 1/2가량 줄이는 경험을 해보았습니다.


# 트러블슈팅

Nest.js로 서비스를 포팅한 후, 예기치 못한 에러에 서비스가 계속 종료되는 일이 발생했습니다. 
Handling이 안되는 에러가 발생하면 서비스가 종료되는 것이었습니다. 그래서 그런 에러가 발생하면 파악해서 처리하려 했으나 말처럼 쉽지 않았습니다.
먼저, 서비스가 종료되는 문제는 Nest.js에서 제공하는 unhandled Error에 대한 Error handling을 달아주어 해결했습니다.

그러나 지속적인 모니터링과 에러로깅의 중요성을 깨달았습니다.

그래서 winston이라는 로깅 라이브러리로 앱에서 발생하는 모든 로그를 json형식으로 정형화 한 후, ELK 스택을 적용하여 web에서 모니터링할 수 있게 했습니다.

그 결과 현재는 에러가 발생하면 간단히 web에 접속하여 확인할 수 있습니다.
여기서 멈추지 않고, 시간이 오래걸리는 api를 분석하거나 요청이 많이 들어오는 api를 분석하는 등 사용하고 있습니다.

