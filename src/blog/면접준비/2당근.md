### 이런 일을 해요

- 초당 수천 개의 요청과 메시지 트래픽을 효율적이고 안정적으로 처리하는 Event-Driven 아키텍처를 고민해요
- OOP, FP, Resolver 패턴을 적재적소에 활용하여  구인·구직 도메인의 복잡한 문제를 해결해요
- 구인구직 서비스에 필요한 다양한 GraphQL API 를 개발하고 유지 보수해요
- 구인·구직 서비스의 운영을 자동화하고, 데이터 기반 의사결정을 돕는 효율적인 백오피스를 구축해요
- 로그 분석, 실험 분석 등 데이터 기반의 의사결정에 필요한 데이터를 정제하고 가공해요

### 이런 분을 찾고 있어요

- 내가 만드는 제품을 통해 유저에게 가치를 전달하는 것에 동기부여가 되시는 분
- 제품 중심으로 생각하며 그에 맞는 문제 정의 및 해결책을 도출하시는 분
- 자기 주도적이며 빠른 실행력을 가지신 분
- 하나 이상의 프로그래밍 언어를 깊게 탐구해 보신 분
- RDBMS, NoSQL 등 데이터베이스를 활용해본 경험이 있으며 이에 대한 이해가 있으신 분

### 이런 분이면 더 좋아요!

- Node.js, Go를 활용해 본 경험이 있으신 분
- GraphQL을 활용해 본 경험이 있으시거나 관심이 있으신 분
- React 기반 클라이언트 개발이 가능하신 분

- Node.js, Go
- MongoDB, Redis, Kafka
- GraphQL, gRPC이렇게 합류해요


# Event Driven Architecture

이벤트를 중심으로 데이터 흐름과 처리를 구성하는 아키텍처
어떤 이벤트가 발생하면, 발행한다.
소비자가 구독 형태로 이를 받는다.

기능 확장 시 다른 컴포넌트에 영향을 주지 않아 확장성이 좋다.
새로운 이벤트 추가, 구독 추가 확장이 쉽다.
이벤트 발생과 처리 시점이 분리되므로, 다양한 이벤트를 동시에 효율적으로 관리 가능하다.

이벤트가 많아질수록 이벤트 플로우를 추적하기가 어려워진다.
비동기 처리가 주가 되므로 즉각적인 일관성 보장이 어렵다.

## 트래픽이 많은 경우 EDA가 유리한가?
많은 요청을 한번에 처리하려면, 요청을 빠르게 큐에 쌓고 비동기적으로 처리할 수 있어야한다.
EDA에서 Kafka, Redis stream을 이용해 소비자가 이를 빠르게 처리하도록 구성이 가능합니다.

트래픽 증가 시, Producer만 혹은 Consumer만 확장이 가능합니다. 트래픽 증가에 유연하게 대처 가능합니다.

이벤트 메시지가 저장되어 있으면 장애가 나도 재처리가 가능합니다.

이벤트 흐름이 잘 파악된다면, 병목지점을 찾을 수 있습니다.


Kafka, RabbitMQ등 개념 알아두면 좋음
(Kafka의 파티션, 오프셋 개념, RabbitMQ의 Exchange 타입(Direct, Topic, Fanout 등), 큐 바인딩 등.)

메시지를 발행하고, 동시에 어떻게 응답 반환할지 고민

## +
저는 전체시스템을 EDA로 구성해본 적은 없지만, 알림기능을 메시지 큐를 활용한다던가, Spring에서 Java의 이벤트 방식을 사용해본 경험이 있습니다. EDA 아키텍처가 장애 재처리가 가능하고 여러 요청을 수용 가능하다는 점에서 매력적이라 당근에서 제대로 한번 경험해보고 싶습니다.

Consumer의 스케일 조절도 중요할것 같습니다. 비동기 프로세스 모니터링. 갑작스럽게 요청 증가했을 때 대응할 수 있도록.
Kubernetes를 사용한다던가, 하면 좋을듯. 



# OOP

클래스로 표현하고, 필요한 속성과 메서드를 묶어 캡슐화.
추상화, 상속, 다형성등을 통해 비즈니스 로직을 정리 (예를 들어 ‘정규직 채용공고’와 ‘프리랜서 채용공고’가 상속 관계로 구성되어, 공통된 속성은 상위 클래스에 정의하고, 구체적인 차이는 하위 클래스가 구현하는 식으로 복잡도를 줄일 수 있어요.)
객체간 협력으로 로직 분산

# FP (Functional Programming)
순수 함수, 불변 데이터를 지향합니다.
함수는 입력 -> 출력이 명확해야하고, 사이드 이펙트를 최소화 해야합니다.

구직자와 채용공고 데이터를 한꺼번에 매칭할 때, 특정 조건으로 필터링할 때, 맵/필터/리듀서 등의 함수형 스타일이 오류를 줄여줄 수 있다.

병렬 처리에 유리. 상태 공유가 적어, 이벤트 스트리밍 환경에서 병렬처리가 유리하다.

# Resolver 패턴

GraphQL에서 데이터를 가져오기 위한 함수. 
Query 또는 Mutation이 들어오면, 해당하는 함수를 Resolver라고 부른다.


의존성을 주입하거나 어떤 객체가 처리할지 정하는것도 Resolver

# GraphQL

클라이언트가 필요한 데이터만 정확히 요청하여 응답받을 수 있다.
쿼리 언어이제 스펙

OverFetching, UnderFetching 해결
Restful API에서는 /users, /users/:id/posts 등 쪼개서 받는 경우가 많다.

GraphQL에서는 한번의 쿼리로 데이터 구조를 자유롭게 정의해서 받을 수 있다.
요청과 응답 구조가 스키마로 명확히 정의된다.

## 스키마
GraphQL 서버가 제공하는 데이터 구조와 API 명세를 정의.
Query: 데이터 조회
Mutation: 데이터 수정
Subscription: 실시간 이벤트 전송

## 타입
스키마에서 각 객체가 어떤 필드를 가지고, 필드 타입이 무엇인지 정의

## Query & Mutation

## Resolver
쿼리, 뮤테이션을 처리하는 함수
`jobPosting(id: ID!)` 이라는 쿼리에 대해, DB에서 해당 `id`의 채용공고를 가져오는 로직이 Resolver에 존재.


- 나는 왜 당근에 지원했는가?
- 인간관계 내 갈등이 있었다면 어떻게 해결을 했는가?
- 나의 장, 단점은 무엇인가
- 직무 인터뷰때 아쉬웠던 점에 대한 복기
- 동료에게 피드백을 어떻게 하는 편이고 피드백을 잘 수용하는 편인가?
- 토스에서 이루고 싶은 목표는 무엇인가?

제장점은 의사소통에 강점이 있다는 것입니다. 제 의견을 설득력있게 잘 전달할 수 있고, 다양한 환경에서 예를 들면 교환학생 의사소통 해본 경험이 있습니다.

제 단점은 모든걸 완벽하게 하려고 하는 것입니다. 예를 들면, 기술을 적요할때도 적용해보면서 배우는 방법이 효율적인데 완벽히 알고 사용해보려 해서 시간이 지체 된다거나하는 일이 종종 있습니다.


# Redis란 무엇인가요?
메모리 기반의 데이터 저장소로, 높은 처리량과 빠른 성능을 제공하기 위한 Key-Value 방식의 NoSQL 데이터베이스입니다.
List, Set, Sorted Set, Hash 등 다양한 자료구조를 지원합니다.
In-Mamory 구조이므로 매우빠른 읽기, 쓰기 속도를 가집니다.

- 캐싱
- Session저장소
- Pub/sub
- 레디스 클러스터
로 사용가능합니다.

메모리 기반이라 매우 빠르지만, 메모리 비용이 많이 듭니다.
싱글 스레드로 작동합니다.
디스크에 작성하는 시점에 따라 장애 발생 시 일부 손실 가능성이 있습니다.

# Kafka란 무엇인가요?
분산 스트리밍 플랫폼으로, 대용량의 데이터를 안정적으로 실시간으로 처리하고 전달하기 위해 사용합니다.

Publish, Subscribe 패턴을 기반으로 하는 메시지 보로커이며, 분산 환경에 적합하도록 높은 확장성과 내결함성을 제공합니다.

데이터는 토픽 단위로 저장되고, 각 토픽은 여러 파티션으로 나뉘어 병렬 처리와 확장성을 극대화합니다.

Producer: 메시지를 작성하여 특정 토픽에 전송
Broker: 메시지를 저장, 관리하는 Kafka 서버. 보통 여러 Broker로 구성하여 클러스터 형태로 동작
Consumer: 토픽으로부터 메시지를 구독하고, 필요한 데이터를 가져가는 역할
Topic: 메시지가 저장되는 논리적인 개념. 각 토픽은 파티션을 가지고 파티션은 물리적으로 메시지를 저장
Zookeeper: 클러스터 메타데이터 관리. Kraft 추가됨

메시지를 가져간다고 삭제되지 않음. 메시지는 설정된 기간동안 보관됨.
Consumer는 Consumer Group 단위로 오프셋을 관리. 어떤 Consumer Group이 어느 시점까지 읽었는가를 추적.
# GraphQL이란 무엇인가요?

Facebook이 개발한 쿼리 언어. 클라이언트가 필요한 데이터만 선택적으로 요청할 수 있는 API 규격.
REST API는 엔트포인트별로 정해진 형식의 데이터 응답을 제공하지만, GraphQL은 단일 엔드포인트에서 다양한 형태의 요청과 응답을 처리

- Schema 정의. 데이터 타입과 관계를 정의하는 스키마 가진다.
- Query: 읽기 전용 요청
- Mutation: 데이터 변경
- Resolver: Query나 Mutation에서 요청된 필드별로 실제 데이터를 어떻게 가져올지를 정의한 함수.
- 단일 엔드포인트로 모든 요청을 처리

단점은
- 캐싱이 어렵다.
- 클라이언트가 복잡하거나 중첩된 쿼리 요청하면 부하가 커짐.
- N+1문제. Data Resolver로 해결.


# gPRC란?
Google에서 개발한 범용 원격 프로시저 호출.
Telefunc라는걸 사용해본 경험이 있습니다.
MicroService가 늘어나면서, 서비스 간 통신을 좀 더 효율적이고 표준화된 방식으로 처리할 필요가 생김.
바이너리 직렬화 포맷 및 HTTP/2 기반 스트리밍을 결합한 gRPC 등장

클라이언트 스텁과 서버스텁이 내부적으로 프로세스 진행
## 장 점
고성능, 저오버헤드
엄격한 스키마와 타입 안전성: .proto 파일에 메시지 구조와 RPC함수를 정의하고, 이를 바탕으로 서버/클라 코드를 자동생성
개발시점에 타입에러 잡을 수 있다.

엄격한 스키마 덕에 대규모 팀 프로젝트에서 협업, 버전 관리에 용이
