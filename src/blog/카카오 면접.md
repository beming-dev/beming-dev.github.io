
Server, Client, Platform, Infra 등 다양한 분야가 유기적으로 협력하며 하나의 서비스를 완성합니다. 이곳에서 개발자는 대규모 서비스를 설계하고, 안정적으로 운영하며, 사용자 경험을 끊임없이 개선하는 전 과정을 함께합니다.

전 국민이 사용하는 카카오톡과 같은 대규모 서비스의 서버 애플리케이션을 개발하고, 이러한 서비스가 안정적으로 운영될 수 있도록 최고 수준의 IT 인프라와 내부 개발자 플랫폼을 설계, 구축, 운영합니다. 또한 사용자와 직접 닿는 클라이언트 서비스를 유려하게 구현하고, 서비스 운영 과정에서 발생하는 방대한 데이터를 분석하여 사용자의 경험을 최적화합니다.
## 자기소개

안녕하십니까. 카카오 Tech 직무에 지원하게 된 채민관입니다. 

저는 개발자로서 두가지 핵심역량을 기르기 위해 노력해왔습니다.

첫째, 안정적인 서비스 운영 역량입니다. 수년간 수천명이 이용하는 대학생 모임 플랫폼을 운영하며 안정적인 서비스 운영의 중요성을 배웠습니다. 서비스 운영 중 발생하는 에러에 대응하기 위해 ELK 스택을 도입하여 Docker의 로그를 실시간으로 웹사이트에서 확인할 수 있는 인프라를 구축하고, Redis 캐싱을 활용하여 API의 응답속도를 60%이상 개선해보는 등 다양한 개발 경험을 쌓았습니다.

둘째, 의사소통으로 협업을 만드는 역량입니다. 개발자는 사용자의 요구사항으로 가치를 만들기 때문에 의사소통 역량이 중요하다고 생각합니다. 저는 네덜란드로의 교환학생 경험 중, 창업수업을 수강하며 다양한 문화의 팀원들과 협업한 경험이 있습니다. 이 과정에서 제가 어떠한 환경에도 적응할 수 있고, 의사소통으로 가치를 만들어낼 수 있다는 자신감을 얻었습니다.

이러한 저의 경험을 바탕으로, 카카오에서 동료들과 효율적으로 협업하며, 안정적으로 서비스를 운영하며 그 위에서 혁신을 제공하는 개발자가 되겠습니다. 감사합니다.

## 지원동기

제가 카카오에 지원한 이유는 수천만이 이용하는 서비스를 직접 운영해보면서, 그 과정에서 경험할 수 있는 대규모 트래픽에서의 문제, 안정적인 서비스 운영 문제 등을 해결하며 개발자로 성장하고 싶기 때문입니다.

다양한 서비스를 운영해보며, 점점 더 규모가 크고 트래픽이 많은 서비스에서 경험할 수 있는 문제들을 직접 해결하며 성장해보고 싶었습니다. 저도 사용자가 있는 서비스를 운영하며, Redis 캐싱을 적용하여 API 응답 속도를 개선해보고, 코드의 장기적인 유지보수성과 확장성을 위해 클린아키텍처와 도메인주도개발을 공부해보고, ArgoCD를 사용한 GitOps 방식의 배포에 대해서도 공부해보고 적용해보았습니다.

그러나 실제 수천만이 사용하는 서비스에서 경험할 수 있는 것은 한 차원 다른 문제라고 생각합니다. 그리고 카카오에서는 국내 최고의 개발자들과 함께, 현업에서 이런 문제를 해결하며 성장할 수 있다 생각하였고, 그래서 지원하게 됐습니다.


## 입사후 원하는 모습.

## 꿈을 물어봤음

## 5년후 10년후 어떤 개발자가 되기 원하는지

저는 시스템에 필요한 요구사항을 빠르게 파악하고 끊임없이 공부하여 다양한 요구사항을 폭넓은 기술 스택으로 효율적으로 처리하는 개발자가 되고 싶습니다.

"소프트웨어 개발의 복잡성을 한번에 해결해주는 은탄환은 없다" 라는 말이 있듯이, 개발을 할 수록 부족한 부분, 보완할 부분이 보이고 더 나은 것에 대해 끊임없이 고민하게 되는 것 같습니다. 그래서 개발자에게 더더욱 경험과 공부가 중요하다고 생각합니다.

그래서 저는 카카오와 같은 대규모 서비스를 운영하고, 또 수많은 사용자가 사용하는 신규 개발도 해보면서 끊임없이 성장하고 싶습니다. 그렇게 최종적으로는, 개발 과정에서 생기는 문제나 요구사항을 유연하게 해결하는 개발자로 성장하고 싶습니다.

## 어떤 직무에서 일하고 싶나요?

서버와 인프라가 1순위이고, 플랫폼이 2순위입니다.

서버와 인프라가 1순위인 이유는, 그동안 제가 해왔던 개발과 가장 맞닿아 있어, 빠르게 기여할 수 있고, 또 대규모 트래픽에 대해 고민하며 제가 가장 성장할 수 있는 환경이라 생각하기 때문입니다.

먼저, 클라우드 환경에서 어떻게 시스템을 구성할지, 아키텍처는 어떻게 사용할지 등 다양하게 고민해보았습니다. 그리고 Redis, Elasiticsearch와 같은 기술을 실제로 서비스에 적용하고 운영해보았습니다. 이 과정에서 Logstash의 높은 메모리 사용량을 Filebeat로 대체하는 등 그러한 고민도 해보았습니다.

그리고 벡엔드 코드 구조를 잡고, API를 개발하며 주어진 인프라를 활용한 코드를 짜는 것도 자신있는 분야입니다.

플랫폼과 관련해서는, AWS환경에서 CI/CD 파이프라인 구축과 Kubernetes를 활용한 gitops 방식의 배포를 경험해봤습니다. 
빅데이터를 다루는 것도 데이터 엔지니어링에서 하는 업무로 알고 있는데, 이 부분은 제가 좀 약한 부분이라 만약 맡게 된다면 빠르게 공부하고 선배들의 노하우들을 전수받아 빠르게 업무에 적응하겠습니다.

## 강점

## 장단점

## Javascript 동작원리

싱글스레드로 동작하는 언어입니다. 
Javascript의 런타임은 메모리 힙과 콜스택으로 구성되어 있습니다.
즉, Javascript는 하나의 메인스레드와 하나의 콜스택을 갖습니다.
Javascript 자체는 비동기, 논블로킹 작업을 지원하지 않지만, Javascript의 런타임이 담당합니다.

- 코드가 호출되면, 콜 스택에 쌓이고, 코드가 실행되면 Javascript엔진은 비동기 작업을 Web api에게 위임합니다.
- Web api는 해당 비동기 작업을 수행하고, 콜백함수를 이벤트 루프를 통해 태스크 큐에 넘겨주게 됩니다.
- 이벤트 루프는 콜스택에 쌓여있는 함수가 없을 때, 태스크 큐에서 대기하고 있던 콜백함수를 콜스택으로 넘겨줍니다.
- 콜스택에 쌓인 콜백함수가 실행되고, 콜스택에서 제거됩니다.

논블로킹 I/O를 설명하자면, 만약 http 요청이 작업을 동기로 수행했다면, 해당 함수가 콜스택에 쌓인채로 머물러 있고 JS엔진은 해당 작업이 끝날때까지 어떠한 작업도 할 수가 없습니다. 즉, 동기 작업이 다른 코드들을 블로킹합니다.
하지만, Javascript는 비동기 작업을 web api에 넘겨줌으로써, 해당 작업이 완료될때까지 다른 코드들을 실행할 수 있습니다. 이것이 논블로킹입니다.

## Nodejs 의 동작 원리를 설명해주세요.

Node.js란 Javascript를 브라우저 밖에서도 실행될 수 있게 하는 Javascript 런타임입니다.

멀티스레드는 스레드 풀이 늘어날수록 CPU를 소모하고, 요청이 적다면 노는 스레드가 생기는 등 문제가 발생한다. -> Node.js는 싱글스레드 논블로킹 모델로 구성되어 있다. 하나의 스레드로 동작하지만 비동기 I/O작업을 통해 요청들이 서로 블로킹 하지는 않는다.

Node.js는 클러스터링을 통해 프로세스를 fork 하여 멀티스레드처럼 사용될 수 있습니다. -> 확정성이 용이

하지만 Node.js가 완전한 싱글스레드는 아닙니다. 일부 Blocking 작업들은 libuv의 스레드 풀에서 수행됩니다. 

Node.js는 내부적으로 다음으로 구성되어 있습니다.
- Node.js Core Library
- Node.js Bindings
- V8 Engine - javascript -> c++
- libuv

콜백함수들은 libuv 내에 위치한 이벤트 루프에서 관리 및 처리됩니다. 이벤트 루프는 여러 페이즈를 갖고 있고, 각 페이즈들은 각자의 큐를 갖습니다. 

논블로킹 I/O모델은 Input과 Output이 관련된 작업 등의 블로킹 작업들은 백그라운드에서 수행하고, 이를 비동기 콜백함수로 이벤트 루프에 전달하는 것을 말합니다. 
I/O들은 OS커널 혹은 libuv의 스레드 풀에서 담당합니다.(이 스레드 풀은 멀티스레드로 이루어져 있습니다.) 작업이 완료되면 이벤트 루브에 콜백 함수로 등록됩니다. 

이벤트루프는 다음의 6 페이즈를 라운드 로빈 방식으로 순회합니다.
1. timers: setTimeout() 같은 timer함수들이 처리됩니다.
2. pending callbacks: 다음 루프 반복으로 연기된 I/O 완료 결과가 큐에 담깁니다. 
3. 패스
4. poll: I/O와 관련된 콜백을 실행합니다. poll 큐에 쌓인 콜백함수들을 한도가 넘지 않을 때까지 동기적으로 실행.
5. check: 이벤트루프가 poll 단계에서 작업을 수행한 뒤, poll 이벤트를 기다리지 않고 check 단계로 넘어가게 됩니다.
6. close callbacks: close 이벤트에 따른 콜백 실행

## Spring 동작 원리

MVC
- DispatcherServlet: 요청이 발생하면, 코드를 트리거 함.
- HandlerMapping: 요청을 바탕으로 어떤 controller를 실행할지 결정
- Model: Controller에서 View로 넘겨줄 객체가 저장되는 곳
- ViewResolver: view name을 바탕으로 View 객체를 결정

요청이 들어오면 DispatcherServlet이 받아서 HandlerMapping에게 객체를 넘기고, 호출해야할 Controller 메소드 정보를 얻는다.
DispatcherServlet이 HandlerAdapter 객체를 가져온다. HandlerAdapter 객체의 메소드를 실행한다.
Contoller는 비즈니스 로직을 처리하고, 그 결과를 뷰에 전달할 Model 객체에 저장한다.

제어의 역전 IOC를 지원한다. 컨트롤의 제어권이 프레임워크에 있다. 빈에 등록된 객체의 생명주기를 전부 프레임워크가 관리한다.
의존성 주입

AOP: 공통으로 사용하는 기능을 분리하여 관리

## n+1쿼리
학생 리스트가 있고, 각 학생이 여러 과목을 수강하고 있다. 
모든 학생과 학생들이 수강하는 과목 정보를 갖고 오고 싶다.
모든 학생 정보를 갖고 오는 쿼리 한개 + 각 학생별로 과목 정보를 가져오는 쿼리 -> n+1개

어떻게 해결?
- Join 사용
- 배치 쿼리 사용. IN (1,2,3,4) 같은 느낌으로

데이터베이스 쿼리가 너무 많아서 과부화. 네트워크 트래픽 증가. 성능 안좋아짐. 

JPA같은것을 사용할 때 이런 문제 마주할 수 있음. findAll 후 map으로 순회하며 각각 조회

EAGER 방식은 N+1 피할 수 있지만, join이 너무 큰 문제 발생 가능.

LAZY + fetch join이 정석
fetch join은 연관된 엔티티를 실제 객체 그래프까지 함께 가져오도록 강제하는 JPA전용 조인

## 카프카

클러스터, 브로커, 토픽, 파티션, 세그먼트

- 클러스터: 여러대의 브로커로 구성된 시스템. 대량의 데이터를 처리하고, 여러 소비자와 생산자에게 메시지를 제공한다. 
- 브로커: kafka 시스템을 구성하는 개별 서버. 각 브로커는 토픽의 하나 이상의 파티션을 저장하고 관리한다. 이 파티션들에는 메시지 또는 레코드가 순차적으로 저장된다. 
  Producer로부터 데이터를 받아 저장하고, Consumer의 요청에 따라 저장된 데이터를 제공한다.
  브로커에는 리더와 팔로워가 있다. 리더는 모든 읽기 쓰기 작업을 처리하고, 팔로워는 리더의 데이터를 복제한다.
- 토픽: 메시지들의 특정 카테고리 또는 피드를 나타낸다. Producer가 데이터를 보내는 대상이고, Consumer가 데이터를 읽는 출처다. 
- 파티션: 하나의 토픽은 여러 개의 파티션을 갖는다. 이는 Kafka의 확장성과 병렬 처리 능력을 향상시킨다.
  각 파티션은 독립적으로 데이터를 저장하고, 여러 브로커에 걸쳐 분산될 수 있다. 
  각 파티션 내에서 메시지는 순차적으로 저장되며, 이 순서는 파티션 내에서 유지된다.
  시스템 부하가 증가하면, 파티션을 추가하여 처리 능력 확장이 가능하다. 

## Redis
데이터베이스, 캐시, 메시지브로커 등으로 사용됨
디스크가 아닌 메모리에서 데이터를 처리하기 때문에 매우 빠른 데이터 엑세스 속도를 제공

메모리에서 데이터 처리 + 메모리에서 처리된 데이터를 주기적으로 디스크에 동기화해 데이터 유실을 방지

스냅샷, AOF -> 주기적으로 디스크에 저장 + 모든 쓰기 작업을 기록하여 복구

Pub/Sub: 메시지 브로커 역할 수행. 실시간 소통 지원. 특정 채널에 메시지를 발행하면, 이를 구독한 모든 클라이언트가 해당 메시지를 실시간으로 수신하는 구조

메모리 효율적인 관리 필요
- TTL: 불필요한 데이터가 메모리 차지하지 않도록 관리
- 자주 사용되지 않는 데이터 삭제, LRU 알고리즘
- 압축

마스터-슬레이브 복제와 클러스터링으로 높은 가용성 제공하지만, 장애 발생시 데이터 유실 가능성 완전히 배제는 불가.

## Docker
애플리케이션을 쉽게 배포, 공유할 수 있도록 설계된 컨테이너 기반의 오픈소스 가상화 플랫폼.

기존에는 VM을 사용하여 하이퍼바이저 위에 Guest OS를 통째로 설치해야 했지만, Docker의 등장후에는 Docker 위에서 Host OS의 커널을 공유하며 더 가볍게 가상화가 가능해졌습니다.

Docker의 핵심 원리는 리눅스의 두가지 핵심 기능을 바탕으로 만들어졌습니다.
1. 네임스페이스: 격리
   컨테이너의 격리된 뷰를 제공하는 기술입니다. 각각의 컨테이너가 독립된 IP와 포트를 가진 것처럼 격리할 수 있습니다.
2. cgroups: 자원 제한
   컨테이너가 사용할 수 있는 시스템 자원을 제한하고 광리하는 기술입니다.


## 변수와 함수가 저장되는 위치

변수와 함수는 프로그램의 메모리 구조 안에서 정해진 영역에 저장됩니다.

운영체제는 프로세스에게 Code, Data, Stack, Heap 이렇게 네 가지 공간을 할당합니다.

저희가 작성한 코드는 Code 영역에 저장됩니다.

Data영역에는 전역변수와 정적변수가 저장됩니다. 이 변수들은 프로그램 시작부터 끝까지 유지됩니다.

Stack 영역에는 함수 내의 지역 변수와 매개변수가 저장됩니다.

Heap 영역에는 개발자가 코드를 통해 동적으로 할당하는 변수, 객체가 저장됩니다.

재귀함수가 너무 깊이 호출되면 Stack 영역이 가득 차서 프로그램이 비정상적으로 동료될 수도 있습니다.
Heap영역에 할당된 메모리는 사용 후 헤재되지 않으면 가용 메모리가 부족해질 수 있습니다. 가비지 컬렉터가 있긴 합니다.

## 개발 과정에서 가장 풀기 어러웠던 상황은 무었이였는지?

코드 레벨에서는 코드간의 의존성을 제거하는 문제였습니다.
인프라레벨에서는 한정된 인스턴스 자원을 효율적으로 활용하는 문제였습니다.

## 자바 언어의 특징과 객체 지향 설계

자바의 특징은 플랫폼 독립성입니다. JVM이라는 가상 머신 덕분에, 자바 코드는 JVM이 이해할 수 있는 바이트코드로 변환됩니다. JVM이 이 바이트 코드를 OS에 맞게 해석해줍니다.

또한 가비지 컬렉터가 메모리 누수같은걸 막아줍니다. 

또한 객체지향 언어입니다. 

객체지향 설계는 4가지 특징이 있습니다.
1. 캡슐화: 관련된 데이터와 기능을 하나의 캡슐로 묶습니다.
2. 상속: 부모 클래스의 필드와 메서드를 자식 클래스가 물려받아 재사용합니다.
3. 추상화: 객체들의 공통적인 특징을 뽑아내어 인터페이스나 추상 클래스로 정의하는 것입니다. 사용자는 어떻게 구현하는지 알 필요가 없습니다. 
4. 다형성: 오버라이딩이나 인터페이스 구현을 통해 실현됩니다. 부모 타입의 참조 변수가 자식 타입의 객체를 가리킬 수 있게 됩니다. -> 코드가 유연하고 확장 가능해집니다.

## 카카오 서비스 중 불편한점과 어떻게 개선하면 좋을지

pc, 모바일 카카오톡에서 채팅이 엄청 많은 상황에, 검색을 할 때, 매우 위에 있는 데이터를 검색하면 프로세스가 중단되버리는 경험을 몇번 한적이 있습니다.

제가 정확한 원인까지는 알 수 없지만, 채팅 데이터를 풀스캔하는 과정에서 타임아웃이 발생하는 등과 같은 문제일 경우, 검색 결과가 너무 과거의 데이터여서 그 사이의 채팅 내역을 모두 불러오려다 프로세스가 멈추는 경우 이렇게 두가지가 있을 것이라고 생각했습니다.

전자의 경우라면, 사실 제가 내부적으로 어떤 DB를 쓰고 있는지 이러한 자세한 부분까지는 잘 몰라서, 확실한 답을 할 수는 없습니다. 하지만 일반적이라면, ElasticSearch와 같은 역색인 구조를 사용하는 검색 엔진을 사용한다면 좋을것 같습니다. 

후자의 경우라면, 옛날 데이터에서 검색 데이터를 찾았을 때, 모든 데이터를 보내지 않고, 그 당시의 일부 채팅만 전송한 다음 무한 스크롤 방식으로 데이터를 보내는 것이 좋을것 같습니다.


## "`populate`가 문제였다면, 이 API 로직 자체를 수정하는(예: Denormalization(역정규화) 또는 Application-level Join) 방식도 있었을 텐데, 왜 '캐싱'을 먼저 선택하셨나요?"

소모임데이터를 전체를 가져와서 다양한 기준에 따라 가공하여 응답해야했습니다. 그런데 소모임 전체 데이터에 유저정보가 populate 형식으로 돼있었습니다

네 사실 근본적인 해결책은 역정규화가 맞다고 생각을 했습니다. 예를 들어, Comment의 author 닉네임 정도는 중복 저장하는 방식입니다.

캐싱을 선택한 데에는 현실적인 이유가 있었습니다. 먼저, 역정규화는 기존 데이터의 마이그레이션과 기존 로직 수정 등 개발 리소스와 비용이 많이 드는 작업이었습니다. 반면, 캐싱은 기존 로직을 유지하면서 빠르게 문제를 해결할 수 있었습니다. 또한 크기가 큰 데이터를 가공하는 작업을 매 api 요청마다 하는 것 자체가 부담이 될 수 있다 생각하여 캐싱이 낫다 생각했습니다.

## "'네트워크 병목'이 문제였다고 하셨는데, 그것을 어떻게 확신하셨나요? API 응답 데이터의 크기를 직접 확인해 보셨나요?
네, populate 로직을 보고, 데이터가 비대할 것이다 라는 가설을 세운 뒤, 개발자 도구의 네트워크 탭을 통해 Content-Length 값을 확인했습니다. 제 기억에는 당시 이 값이 3MB정도였는데, 매우 높은 수치였던것 같습니다.

## 도메인 주도 개발을 했으면 그런 고민이 필요없지 않았나

네 정확합니다. 먼저 제가 이 문제를 경험한것은 도메인 엔티티 설계를 적용하기 전이었습니다. 도메인 주도 개발이 완벽히 적용됐다면, 

## "데이터를 압축해서 Redis에 저장하셨다고 하셨는데, 어떤 압축 알고리즘(Gzip, Snappy, LZ4 등)을 사용하셨나요? 그리고 그 알고리즘을 선택한 이유가 있나요?"

GZip을 사용했습니다 텍스트 기반의 JSON데이터에서 매우 높은 압축률을 보여줍니다. 5MB에 달하던 payload를 수백 KB 수준으로 줄여주었습니다.

## 압축은 CPU 사용할텐데
제가 그 부분까진 생각을 못했습니다. 면접 후에, Metric 데이터도 수집하여 CPU 사용량에 큰 변화가 있는지 확인해보는것도 좋을것 같습니다.

## "Service가 데이터베이스의 **영속성 모델(Entity)에 의존하는 것**이 **왜 문제**라고 생각하셨나요? 개발할 때 구체적으로 어떤 불편함이 있었죠?"

처음 repository를 interface를 사용해서 분리한 목적이, DB의 의존성을 제거하는 것이었습니다. 그런데, DB에서 조회한 내용을 그대로 service 코드에서 사용한다면, DB의 로직이 바뀌면 여전히 service코드도 수정이 필요해집니다. 하지만 service에서 사용할 도메인 엔티티를 사용한다면, repository에서 전환 과정을 통해 의존성을 완전히 제거할 수 있게 됩니다.

## "언급하신 **'도메인 모델'과 '영속성 모델'의 가장 큰 차이**가 무엇이라고 생각하시나요? 그리고 이 둘을 분리하면서 발생한 **매핑(Mapping) 비용(오버헤드)**은 어떻게 처리하셨나요?"

영속성 모델은 데이터베이스와 통신하기 위한, DB 테이블의 구조입니다. DB스키마 구조와 1:1로 매핑되고, ORM과 같은 기술과 강하게 의존됩니다.
반면, 도메인 모델은 도메인에 필요한 내용을 저장하고, 비즈니스 규칙과 로직을 수행합니다. 이는 DB나 외부 기술에 대해 전혀 알지 못하는 순수한 객체여야 합니다.
테스트가 용이해집니다. DB연결 없이도, 도메인 모델의 순수한 유닛 테스트가 가능해집니다.
## "DDD를 공부하셨다고 했는데, **어떤 개념(e.g., Aggregate, Value Object, Repository 패턴)**을 적용하셨고, 그게 왜 이 문제를 해결하는 데 도움이 되었나요?"

Value Object는 교체는 되어도, 수정은 안되는 객체입니다. 식별자가 아닌 값 자체로 구분되는 객체입니다.

Aggregate: 일관성을 책임지는 데이터 묶음 스터디는 참여자, 시간 등의 정보를 포함할 수 있습니다. 이를 묶은 대장을 Aggregate root라고 합니다. 이들의 데이터를 변경할때는 루트를 통해서만 이뤄져야 합니다.

entity는 생명주기가 있어 변경 가능하다. VO는 생명주기가 없고, 불변성을 가진다. 비즈니스 로직의 복잡성을 줄이고 코드의 의미를 명확하게 하기 위해 사용한다. 데이터 유효성 검증, 일관성 유지 등을 쉽게 관리할 수 있습니다.

## "**'핵심 비즈니스 로직이 도메인으로 이동했다'**고 하셨는데, **구체적으로 어떤 코드**가 Service 계층에서 Domain 객체로 이동했는지 **예시**를 들어 설명해 주실 수 있나요?"

저희 서비스의 핵심 도메인은 스터디를 예로 들면, 스터디에 참여할 때 인원, 중복참여 체크 등등을 도메인 로직으로 옮겼습니다. 또, 스터디를 불참할때나 참석했을때 상태를 변경하는것 등등도 옮겼습니다.

## - Controller와 Service 사이의 원칙 적용이 실효성이 적었다고 하셨는데, 구체적으로 **어떤 원칙을 적용하려 하셨던 건가요?** (아마도 Service Interface?) 그리고 **왜 그게 실효성이 적다고 판단**하셨죠?"

네 처음에는 추상화가 무조건 좋다고 생각하여 service의 interface도 작성하였습니다. 그러나 service코드의 interface를 작성하는 것은 그럴듯한 장저밍 없었습니다. service 코드의 반환 타입만 잘 적용해두면, service 코드의 변경이 controller에 그닥 영향을 미치지 않고, 클린아키텍처 관점에서도 controller가 service에 의존하는 것은 크게 문제가 없었습니다. 그리고 interface를 적용하는 것이 오히려 srevice에 메소드를 추가할 때 추가적인 작업을 해야해서 더 개발 비용만 증가했습니다.
    

## "본인 스스로 **'이 정도면 충분하다'는 생각**과 **'완성도를 높여야 한다'는 생각이 충돌**할 텐데요. **어떤 기준**으로 '멈출 때'와 '더 나아갈 때'를 판단하시나요?"

더 나은 구조에 대해 끊임없이 고민하는 것은 필요하다고 생각합니다. 신규 기능 개발로 인해, 

## - "마지막에 '모듈을 독립적으로 배포할 수 있는 구조'를 고민 중이라고 하셨는데, **모듈형 모놀리스**나 **마이크로서비스(MSA)**를 의미하시는 건가요? 현재 구조에서 그 단계로 나아가는 데 있어 **가장 큰 기술적 장벽**은 무엇이라고 생각하세요?"

네 맞습니다. MSA 적용을 의미했습니다. 그러나 사실 저희 서비스가 아직 MSA를 도입할 필요는 없습니다. 개발팀의 크기도 2명일 뿐더러, 트래픽도 엄청 큰수준은 아니기 때문입니다. 오히려, MSA를 도입하면 데이터 일관성 문제나 통신 문제등 개발 비용만 증가하게 될 것입니다. 그래서 가장 좋은 방법은 서비스를 언제든 독립적으로 배포할 수 있도록 분리해놓돼, 모놀리틱 구조를 유지하는 것입니다. 그리고 이게 지금 제가 추구하고 있는 아키텍처입니다. MSA 구조의 도입이 필요한 때가 오면, 비용을 최소화하여 도입할 수 있도록 하고 싶습니다.
가장 큰 기술적 장벽은 아무래도 데이터 일관성 문제일 것 같습니다. 서비스 특정 MS에서 문제가 생기면, 보상 트랜잭션등을 통해 데이터가 항상 최종적 일관성을 지닐 수 있도록 많은 고민이 필요할 것 같습니다. 이벤트 드라이븐 아키텍처




## Priority Queue (우선순위 큐) 구현 방법
우선순위 큐를 구현하기 위해선 힙 자료구조를 사용할 수 있습니다. 힙은 항상 우선순위가 높은 데이터가 먼저 나오는 자료구조입니다. 부모노드가 항상 자식 노드보다 큰 값 또는 작은값을 가집니다. 값을 추가할 때는 맨 마지막에 값을 넣고, 조건을 만족할 때 까지 부모 노드와 교체합니다. 데이터를 삭제할 때는 루트 노드 값을 제거하고, 마지막 값을 루트에 넣은 다음, 조건을 만족할 때까지 자식과 위치를 바꿉니다.

## - Stack, Queue의 차이 및 사용되는 예시
Stack은 나중에 들어간 데이터가 먼저 나오는 LIFO
Queue는 먼저 들어간 데이터가 먼저 나오는 FIFO 방식입니다.

Stack은 재귀함수를 호출 할 때, 순서대로 stack에 쌓이며 실행되는 방식으로 사용합니다.
queue는 javascript에서 비동기 작업을 처리할 때, 비동기 작업에 완료되면 콜백큐로 옮겨지고, 이벤트 루프에 의해 먼저 완료된 작업이 먼저 콜스택으로 옮겨지게 됩니다.

## - HashTable 설명과 해시 충돌 해결 방법
HashTable은 값을 해시함수에 넣고 나온 결과에 따라 데이터가 저장될 위치를 결정합니다. 이 때, 해시 충돌이 날 수 있는데, 바로 다음 저장공간에 저장하는 방법이 있고, chain을 사용하요 연결 리스트 방식으로 쭉 이어서 사용하는 방법이 있습니다.

## - Thread, Process 설명
Process는 실행중인 프로그램을 말합니다. 
Thread는 Process내에서 작업을 처리하는 단위입니다. 스레드는 각자의 스택을 가지고 나머지 자원은 공유합니다.

## - DeadLock 설명과 회피 방법
DeadLock은 자원을 점유할 때 4가지 조건이 만족되면 발생할 수 있습니다. 하나의 대상이 하나의 자원만 점유할 수 있는 특성, 다른 자원을 빼앗을 수 없는 속성, 두 개의 대상이 하나의 자원을 점유한 상태에서 서로의 자원을 요청하는 순환대기, 입니다.

자원 획득 순서를 한 방향으로 정하는 방법이 있고, 발생하면 그냥 종료해버리는 방법이 있습니다. 

퀵정렬은 랜덤 피벗값을 고르고, 그 기준에 맞게 파티션을 나누고 합치는 방식으로 알고 있습니다. 이 때, 데이터를 0개와 N-1개로 나누는 최악의 피벗을 계속 선택하게 되면 O(N^2)의 복잡도가 나오게 될 것 같습니다.

대칭키 암호화는 동일한키로 암복호화 하는 것입니다. 속도가 매우 빠르지만, 키 배송 문제가 있습니다.
비대칭키 암호화는 공개키와 개인키를 이용합니다. 공개키로 데이터를 암호화하면 개인키를 가진 사람만이 열 수 있습니다.
해시함수: 복호화가 불가능한 단방향 암호화입니다. 원본을 절ㅈ대 알 수 없습니다. 복호화가 불가능하기 때문에 비밀번호를 저장하는 등에 사용합니다.

한정된 자원에 접근할 때는 상호 배제를 보장해야 합니다.
- 뮤텍스: 공유 자원에 접근하는 영역을 임계 구역으로 지정하고, 하나의 락으로 보호합니다. 락이 점유하고 있으면, 대기 상태로 만듭니다. 
- 세마포어: N개까지 접근이 가능하도록 합니다. 자원 요청마다 카운트를 1씩 감소시키고 0이 되면 다음 스레드는 대기합니다. 