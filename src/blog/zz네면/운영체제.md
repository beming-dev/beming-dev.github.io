# 시스템 콜

사용자 프로그램이 운영체제의 서비스를 요청하는 인터페이스
파일I/O, 프로세스 생성/종료, 메모리 할당 등 하드웨어 자원 접근이나 OS 내부 기능을 사용하기 위해 호출

ex) 파일/디렉토리 관련, 프로세스 관리 fork, exec, 메모리관리: mmap, brk, 소켓/네트워크 디바이스 컨트롤

1. 유저 모드에서 시스템 콜 함수 호출
2. 라이브러리 함수가 내부적으로 특수한 소프트웨어 인터럽트 발생 -> CPU를 커널 모드로 전환
3. 커널이 시스템 콜 번호, 인자 확인하고 적절한 커널 함수로 진입
4. 커널 함수가 하드웨어 자원 접근, 처리 등 OS 기능을 수행
5. 처리 완료 후 커널 모드에서 유저 모드로 복귀 & 결과를 유저에게 전달

## 모드
커널모드: CPU가 제한 없이 모든 명령어와 자원 접근
유저모드: 제한된 명령어만 실행 가능

구분 이유
- 사용자 프로그램이 직접 하드웨어나 OS 데이터를 무제한으로 접근하면 위험하다.
- 잘못된 접근을 방지, 커널만이 자원을 통제
- 프로세스 간 보호: 메모리 보호

서로 다른 시스템 콜을 어떻게 구분할 수 있을까?
시스템 콜 진입 시, 레지스터나 스택에 시스템 콜 번호, 인자 전달

# 인터럽트

CPU가 실행 중, 하드웨어 소프트웨어가 특정 이벤트를 알려와 현재 실행 중단하고 이벤트 처리 루틴으로 넘어가는 메커니즘

인터럽트 발생 -> CPI는 PC와 상태 저장
인터럽트 벡터 참조해 적절한 주소 확인
Interrupt Service Routine 실행. 완료 후 복원

Polling: 인터럽트가 아닌, CPU가 특정 I/O 장치를 주기적으로 검사 해 이벤트 발생 여부를 확인하는 방식.

CPU 시간이 낭비될 수 있다. 인터업트 방식이 일반적으로 더 효율적이다.
HW 인터럽트: 하드웨어 신호(키보드 입력, 디스크 I/O)
SW 인터럽트: 소프트웨어적으로 발생.(0나눗셈, 페이지 폴트, 시스템 콜 명령)
인터럽트 간 우선순위 존재

# 프로세스
실행중인 프로그램 + 실행 상태
프로그램: 실행 코드를 담은 정적 파일
프로세스: OS 상에서 실행 중인 프로그램 인스턴스
스레드: 프로세스 내에서 코드/데이터/힙 공유하지만 독립된 실행 흐름 가짐

PCB(Process Control Block)
프로세스 상태를 저장하는 자료구조, 프로세스 식별자, 프로그램 카운터, 레지스터 값, 메모리 정보, 스케줄링 우선순위, 파일 디스크립터 테이블 등

리눅스에서
프로세스는 for()로 복제 -> exec()으로 새 프로그램 실행
스레드는 pthread_creat() 나 clone() syscall로 생성

자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽으면?
자식이 부모에게 exit 알려주지 못하면, 자식은 좀비 프로세스 됨.
부모가 먼저 종료하면 자식은 고아 프로세스가 되어, init 프로세스가 자식 인수하여 wait()대신 호출

## 주소공간
초기화되지 않은 변수들은 어디 저장?
Bulk Storage Start 영역에 저장. 아직 초기값이 설정되지 않은 지역/정적 변수

Stack, Heap은 프로그램 실행 시 운영체제가 가상 메모리를 할당하고, 필요에 따라 확장/축소 함.

스택: 메모리 접근이 지역변수, 함수 호출 스택 프레임 구조. 캐시 친화적이고 주소 단순 계산 -> 힙보다 빠름

힙: 동적으로 할당된 공간을 포인터를 통해 접근

코드 데이터 힙 스택 왜 분리할까?
관리 편의.
힙과 스택을 양쪽에 두면, 서로 충돌하지 않으며 한쪽이 커질 때 유연하게 사용 가능

스레드의 주소공간
프로세스 주소공간 공유하지만, 스택은 스레드마다 독립
text영역, 전역 데이터, 힙 등은 모두 공유

힙은 마구잡이 라는 뜻임

## IPC의 shared Memory 기법
SHared Memory는 mmap()과 같은 시스템 콜로 힙영역에 매핑
커널이 해당 가상 주소 범위를 여러 프로세스의 페이지 테이블에 동일 물리 메모리로 매핑해 공유

스택, 힙 크기는 OS/런타임에 의해 동적으로 결정

# 단기 중기 장기 스케줄러

장기 스케줄러: 어느 프로그램을 메모리에 올려서 프로세스로 만들 것인가?
시분할 시스템ㅇ메서 명시적 장기 스케줄러는 잘 없음

중기 스케줄러: 프로세스를 통째로 스왑 아웃/인 하는 결정. 메모리 부족 시 일부 프로세스 임시 중단

단기 스케줄러: Ready Q 에 있는 프로세스 중 어떤 것을 CPU 할당할지 결정

## 스케줄링 상태
New (생성 중)
Ready (CPU 할당 대기)
Running (CPU 점유)
Blocked (I/O나 이벤트 대기, CPU 미사용)
Terminated (실행 종료)

## preemptive/non-preemptive에서 존재할 수 없는 상태

non-preemptive에서는 프로세스가 스스로 종료하기 전까지 CPU 뺏지 않음 -> Running -> Ready 상태 전이 일어나지 않음.

## 메모리가 부족하다면?
중기 스케줄러가 프로세스를 Suspend상태로 바꿔 디스크로 스왑


# 컨텍스트 스위칭
실행 중인 프로세스의 레지스터, PC, 상태 정보를 PCB/TCB에 저장.
스케줄러가 다음에 실행할 프로세스를 선정
선택된 프로세스의 PCB/TCB에 저장된 레지스터/PC 정보를 CPU 레지스터에 로드
메모리 주소공간도 교체
CPU가 새 프로세스로 실행 재게

프로세스는 주소공간, PCB를 교체하여 상대적으로 무겁다
스레드는 같은 프로세스 내 스레드라면 주소공간 공유하므로, PC, 레지스터, 스택포인터 교체로 충분하다.

기존 프로세스 정보는 PCB/TCB 구조체나 커널 스택에 현재 레지스터, PC, 상태 레이블 등 저장

컨텍스트 스위칭 시점
1. 시분할 타이머 인터럽트
2. I/O 대기로 Blocked
3. 우선순위가 높은 프로세스가 Ready상태로 진입
4. 시스템 콜 중 스케줄러가 의도적으로 선점할 때

# 프로세스 스케줄링 알고리즘
FCFS: First-Come, First-Served
Shortest Job First, Shortest Remaining Time First
Priority 스케줄링
Round Robin
Multi-level Queue / Multi-level Feedback Queue

## RR에서 Time Slice에 따른 Trade-off
Time slice 짧으면 응답 좋아지지만, 문맥 전환 자주 발생 - 오버헤드
길명, 문맥 전환 횟수 작아짐. 대기 시간이 길어짐

## 싱글 스레드 CPU에서 상시 돌아가야 하는 프로세스 있다면?

Priority 스케줄링 또는 무한 우선순위로 배정

동시성과 병렬성 차이
동시선: 실제로는 순차적
병렬성: 멀트코어/프로세서에서 물리적으로 동시 실행

## Multi-level Feedback Queue
여러 우선순위 큐 사용. 프로세스 성격에 따라 동적으로 우선순위를 조정

## 유저 스레드와 커널 스레드의 스케줄링 알고리즘
CPU 스케줄링은 커널이 담당
유저스레드는 라이브러리 수준에서 관리

# 동기화: 뮤텍스, 세마포어
## 뮤텍스
- 상호 배타적 접근을 보장하는 잠금 개념
- 단 한개의 프로세스/스레드만 lock을 얻고, 사용 후 unlock
- Lock을 소유한 스레드가 unlock 해야 하는 ownership 개념이 있음
## 세마포어
- 공유 자원 개수가 의미하는 카운터 혹은 0/1
- 카운팅 세마포어는 여러 자원을 동시에 관리 가능
- 소유 개념이 명확하지 않고, P, V로 카운터를 증가/감소

이진세마포어: 뮤텍스처럼 동작
But,  뮤텍스는 소유한 스레드만 해제 가능

## Spin Lock
1. 임계 구역이 매우 짧을 때, 대기 중 문맥전환 오버헤드보다 바쁜 대기(spin)이 효율적
2. 멀티코어 환경에서 lock을 곧바로 해제할 스레드가 다른 CPU에서 돌고 있으면 빠르게 획득 가능

대기 시간동안 CPU  계속 소모

짧은 임계구역에서만 사용. 일정 시간만 spin

## 뮤텍스/세마포어는 커널이 관리 -> 시스템 콜 호출 필요

커널이 관장하므로, 임계 구역 접근을 확실하게 보장
블로킹 시 OS 스케줄러가 다른 태스크를 CPU에 배정 -> 자원 활용 효율

시스템 콜 오버헤드가 있고
짧은 임계구역에서는 잦은 모드 전환이 비효율적이다.

# Deadlock

둘 이상의 프로세스가 서로의 자원 기다리며 무한 대기
- 상호배제: 한 프로세스만 자원을 점유 가능
- 점유 대기: 한 자원 점유한 상태에서 얻기 위해 대기
- 비선점: 자원 강제로 못뺐음
- 순환 대기: 고리 형태로 자원 대기

네가지 동시게 성립해야함 가능

- 자원을 공유 가능하도록
- 요청할 때 필요한 자원 모두 미리 확보 -> 낭비 큼
- 자원을 선점 가능하도록
- 자원에 일정 순서 부여

## 현대 OS는 Deadlock 처리하지 않음
완벽한 예방, 회피 어려움.
관리자가 수동으로 킬해라

## Wait Free, Lock free

Lock-free: 하나의 스레드가 중단돼도 전체 시스템의 진행이 보장.
CAS등 원자적 연산 활용

Wait-free: 모든 스레드가 유한 시간 안에 연산 완료


# 컴파일
1. 소스코드를 컴파일러가 어휘 분석, 구문 분석, 최적화 -> 목적 코드 생성
2. 링커가 여러 목적 파일, 라이브러리 결합 -> 실행파일
3. 로더가 실행 파일을 메모리에 적재, 런타임 환경을 설정, 프로그램의 시작점으로 점프

## 링커, 로더
링커: 컴파일된 목적 파일 합쳐서 실행 파일 만듦
로더: 실행 파일을 메모리에 적재 하고, 필요한 동적 링킹 실행.

## 컴파일, 인터프리터

컴파일: 전체 코드를 기계어로 변환 후 실행
인터프리터: 실행 시점에 한 줄씩 해석. 속도는 좀 느림

## JIT (Just -In-Time)
실행 중에 자주 쓰이는 코드만 동적으로 컴파일해 기계어로 변경
인터프리터 단점 개선

# IPC
프로세스간 통신 방식

- 파이프
- 메시지 큐
- 공유 메모리
- 소켓
- 시그널

## Shared Mem
물리 메모리를 공유 -> 동기화 반드시 필요. 빠름

## 메시지 큐
양방향도 가능

# Thread Safe
여러 스레드가 접근해도 데이터 불일치나 Race Condition이 발생하지 않는 상태

1. 뮤텍스/세마포어 등 Lock 기법
2. Lock-Free/Wair-Free
3. Thread-Local Storage
4. 불변 객체 설계

## Peterson 알고리즘

## race condition
여러 스레드가 동시에 공유 자원 업데이트 할 때, 실행 순서에 따라 결과 달라짐.

## Thread Safe 구현하려면 반드시 락?
반드시 락이 필요하지는 않음.
Lock-Free나 Wait Free로도 


# 동기화 하드웨어적 해결

## 원자적 명령
test_and_set, compare_and_swap, xchg
여러 스레드가 동시에 접근해도 원자적 락 획득

## volatile의미
컴파일러 최적화 방지
동기화 보장은 x
값이 언제 바뀔지 모름을 컴파일러에 알림

## 멀티코어 동기화
캐시 일관성 프로토콜, 원자적 버스 잠금 사용
원자적 연산 시 버스 또는 캐시 라인 잠금으로 동시 업데이트 막고 순차적 동작 보장.

# 페이지 교체 알고리즘

## LRu 구현

Linked List + 해시

# File descriptor & File System
OS가 파일 열 때 반환하는 추상 핸들 정수
각 프로세스마다 FD 테이블 있으며, FD를 통해 파일에 읽기 쓰기 가능

## INode
유닉스 계열 파일 시스템에서 파일 메타데이터를 저장한 구조체

파일명은 디렉터리, 실제 데이터 위치는 I-NODE

# 블로킹 논블로킹
블로킹: I/O 요청 시 호출 스레드가 잠들어서 다른 작업 불가.
논블로킹: I/O 요청 시 즉시 반환, 스레드는 계속 진행